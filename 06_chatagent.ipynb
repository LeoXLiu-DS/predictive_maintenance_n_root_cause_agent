{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42798886-ad4c-452a-8ddd-1ffe4ff3acf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Enables autoreload; learn more at https://docs.databricks.com/en/files/workspace-modules.html#autoreload-for-python-modules\n",
    "# To disable autoreload; run %autoreload 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3e371dd-ba51-471b-b803-6d178204445a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Predictive Maintenance Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30dcbb58-218b-450e-b70f-fca8c68607a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U langchain langgraph databricks-sdk databricks-vectorsearch\n",
    "%pip install databricks-sdk[openai]\n",
    "%pip install grandalf\n",
    "%pip install pyppeteer\n",
    "%pip install -U databricks-agents>=0.16.0 mlflow>=2.20.2 databricks-langchain databricks-openai\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76bb820c-5f26-4310-a96c-8c1d9091e8c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatDatabricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "028200f1-6b74-49ca-b0a3-5605ce0d3d52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "llm = ChatDatabricks(\n",
    "    target_uri=\"databricks\",\n",
    "    endpoint=\"databricks-llama-2-70b-chat\",\n",
    "    temperature=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdff0e30-0695-4932-93ad-a581bcff9574",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow, mlflow.langchain\n",
    "mlflow.langchain.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "710202fe-3a07-44b3-b9e1-f37ac2755653",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "from databricks.sdk import WorkspaceClient\n",
    "import pickle\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import mlflow\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8408faf-a8a2-4b31-be81-31dd9c6ab861",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14b6847a-3b67-416e-9a08-fc4cc9419717",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "LLM_MODEL = \"gpt-41\"\n",
    "llm = ChatDatabricks(\n",
    "    target_uri=\"databricks\",\n",
    "    endpoint=LLM_MODEL,\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "print(llm.invoke(\"What is MLflow?\").content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1cbb8e7-34d2-46d6-8acf-86c4134ff3a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.chat_models.base import BaseChatModel\n",
    "from langchain_core.tools import tool\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_community.chat_models.databricks import ChatDatabricks\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "import mlflow\n",
    "\n",
    "\n",
    "# Configure\n",
    "catalog = \"workspace\"\n",
    "schema = \"genai_demo\"\n",
    "model_name = \"isolation_forest_pm_model\"\n",
    "model_version = 1\n",
    "AD_MODEL = f'models:/{model_name}/{model_version}'\n",
    "VECTOR_INDEX = \"workspace.genai_demo.maintenance_docs_index\"\n",
    "# EMBEDDING_MODEL = \"databricks-gte-large-en\"\n",
    "# LLM_MODEL = \"databricks-llama-4-maverick\"\n",
    "LLM_MODEL = \"gpt-41\"\n",
    "\n",
    "\n",
    "# Load resources: model, retriever, LLM\n",
    "ad_model = mlflow.sklearn.load_model(AD_MODEL)\n",
    "\n",
    "# vsc = VectorSearchClient()\n",
    "# index = vsc.get_index(index_name=VECTOR_INDEX)  # adjust catalog/schema\n",
    "\n",
    "# ws = WorkspaceClient()\n",
    "# chat_client = ws.serving_endpoints.get_open_ai_client()\n",
    "llm = ChatDatabricks(\n",
    "    target_uri=\"databricks\",\n",
    "    endpoint=LLM_MODEL,\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "# Define tools\n",
    "@tool\n",
    "def anomaly_detector(vibration: float, pressure: float, temperature: float) -> str:\n",
    "    \"\"\"\n",
    "    Detects anomalies in equipment behavior using vibration, pressure, and temperature.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        prediction = ad_model.predict([[vibration, pressure, temperature]])\n",
    "        result = \"Anomalous\" if prediction[0] == -1 else \"Normal\"\n",
    "        return f\"Anomaly Detection Result: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    \n",
    "\n",
    "@tool\n",
    "def vector_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Searches the vector index for machine manual documents.\"\"\"\n",
    "    try:\n",
    "        # Search the index with the query string\n",
    "        # results = index.similarity_search(query)\n",
    "        # return \"\\n\".join([str(res) for res in results])\n",
    "        return \"The machine's bearings are wore down and need to be replaced.\"\n",
    "    except Exception as e:\n",
    "        return f\"Vector search error: {str(e)}\"\n",
    "\n",
    "\n",
    "tools = [anomaly_detector, vector_search]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "# Define Nodes\n",
    "system_prompt = SystemMessage(\n",
    "    content=(\n",
    "        \"You are a predictive maintenance engineer. Answer machine maintenance queries using the search index. \"\n",
    "        \"If sensor data is provided, use the anomaly detection tool. \"\n",
    "        \"If the machine is anomalous, ask user whether RCA and resolution is required if user does not suggest anything otherwise continue the task.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "def assistant_node(state: AgentState) -> AgentState:\n",
    "    msgs = state[\"messages\"]\n",
    "    # Prepend system prompt if first turn\n",
    "    if not any(isinstance(m, SystemMessage) for m in msgs):\n",
    "        msgs = [system_prompt] + msgs\n",
    "\n",
    "    response = llm_with_tools.invoke(msgs)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Tools node for execution\n",
    "tools_node = ToolNode(tools)\n",
    "\n",
    "# Add memory\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "def create_agent():\n",
    "    builder = StateGraph(AgentState)\n",
    "    builder.add_node(\"assistant\", assistant_node)\n",
    "    builder.add_node(\"tools\", tools_node)\n",
    "\n",
    "    builder.add_edge(START, \"assistant\")\n",
    "    builder.add_conditional_edges(\n",
    "        \"assistant\",\n",
    "        tools_condition\n",
    "    )\n",
    "    builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "    agent = builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "    return agent\n",
    "pm_agent = create_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "390d2a0c-c011-42f1-8169-035547e46e74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "# messages = [HumanMessage(content=\"The machine's vibration is 3.2, pressure is 45, temperature is 78. If the machine is anomalous, please do a detail RCA and suggest a resolution.\")]\n",
    "# messages = [HumanMessage(content=\"The machine's vibration is 3.2, pressure is 45, temperature is 78.\")]\n",
    "messages = [HumanMessage(content=\"My machine is running very hot, I am wondering what the cuase is and how I can solve it.\")]\n",
    "response = pm_agent.invoke({\"messages\": messages,}, config)\n",
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4aa63733-ace7-4743-b453-255d7729f82e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# messages = response['messages'] + [HumanMessage(content=\"yes, pleasse\")]\n",
    "messages = [HumanMessage(content=\"yes, please\")]\n",
    "response = pm_agent.invoke({\"messages\": messages}, config)\n",
    "\n",
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb0143df-9c51-41aa-a8df-0abda91beb0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bdccfa9e-9a2f-4ec2-8dba-b22e9162b14f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b7bd347-7556-4ade-b6f3-82c73cffffaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "129dea31-8a47-4c89-9b71-9e841c5a3925",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7fa1eb8-a410-4943-bd6b-16eaa0923dab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define Nodes\n",
    "def detect_anomaly(state: AgentState) -> dict:\n",
    "    X = [[state.temperature, state.vibration, state.pressure]]\n",
    "    state.is_anomaly = ad_model.predict(X)[0] == -1\n",
    "    return {\"is_anomaly\": state.is_anomaly}\n",
    "\n",
    "def rca_with_query_optimization(state: AgentState):\n",
    "    # 1. Optimize query\n",
    "    raw_query = (f\"Machine {state.machine_id} anomaly: T={state.temperature} [normal {state.normal_temp[0] - state.normal_temp[1]}], \"\n",
    "                 f\"V={state.vibration} [normal {state.normal_vibration[0]} - {state.normal_vibration[1]}], \"\n",
    "                 f\"P={state.pressure} [normal {state.normal_pressure[0]} - {state.normal_pressure[1]}]\")\n",
    "    q_opt_msg = [\n",
    "        {\"role\":\"system\",\"content\":\"Rewrite the following to a concise, technical search query focusing on deviation from normal operation.\"},\n",
    "        {\"role\":\"user\",\"content\":raw_query}\n",
    "    ]\n",
    "    q_opt = chat_client.chat.completions.create(model=LLM_MODEL, messages=q_opt_msg).choices[0].message.content\n",
    "    state.query = q_opt\n",
    "\n",
    "    # 2. Retrieve relevant documents\n",
    "    hits = index.similarity_search(query_text=q_opt, columns=[\"chunk_text\"], num_results=2, query_type=\"hybrid\")\n",
    "    context = \"\\n\\n\".join(hit[0] for hit in hits[\"result\"][\"data_array\"])\n",
    "    state.context = context\n",
    "    # 3. Generate root cause & action\n",
    "    prompt = [\n",
    "        {\"role\":\"system\",\"content\":\"You're an engineer analyzing machinery anomalies.\"},\n",
    "        {\"role\":\"user\",\"content\":\n",
    "         f\"Anomaly details:\\n{raw_query}\\n\\nContext:\\n{context}\\n\\nProvide root cause and maintenance actions.\"}\n",
    "    ]\n",
    "    response = chat_client.chat.completions.create(model=LLM_MODEL, messages=prompt)\n",
    "    suggestion = response.choices[0].message.content\n",
    "    state.suggestion = suggestion\n",
    "    return {\"suggestion\": suggestion}\n",
    "\n",
    "\n",
    "def normal(state: AgentState) -> dict:\n",
    "    suggestion = \"✅ Machine is operating properly.\"\n",
    "    state.suggestion = suggestion\n",
    "    return {\"suggestion\": \"✅ Machine is operating properly.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5a47972-05f6-4577-a914-cc737b109466",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Build the LangGraph\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"detect_anomaly\", detect_anomaly)\n",
    "workflow.add_node(\"rca\", rca_with_query_optimization)\n",
    "workflow.add_edge(START, \"detect_anomaly\")\n",
    "workflow.add_conditional_edges(\"detect_anomaly\",\n",
    "    lambda s: \"rca\" if s.is_anomaly else \"normal\",\n",
    "    {\"rca\":\"rca\", \"normal\": \"normal\"}\n",
    ")\n",
    "workflow.add_node(\"normal\", normal)\n",
    "workflow.add_edge(\"normal\", END)\n",
    "workflow.add_edge(\"rca\", END)\n",
    "\n",
    "agent = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74f74fc3-b693-451b-b8a6-32f015b86a5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(agent.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41f9178e-7069-488e-8a97-a468be81599b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "# test = {\n",
    "#     \"timestamp\": datetime.now(),\n",
    "#     \"machine_id\": 2,\n",
    "#     \"temperature\": 60.5,\n",
    "#     \"vibration\": 3.7,\n",
    "#     \"pressure\": 27.2,\n",
    "# }\n",
    "\n",
    "test = {\n",
    "    \"timestamp\": datetime.now(),\n",
    "    \"machine_id\": 2,\n",
    "    \"temperature\": 25,\n",
    "    \"vibration\": 1.5,\n",
    "    \"pressure\": 3,\n",
    "}\n",
    "print(agent.invoke(test)[\"suggestion\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4986fc28-dad4-4bcc-89d2-620300f1d515",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Wrap the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f02707f-2e61-43df-acab-f51821020e70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from mlflow.deployments import get_deploy_client\n",
    "# import mlflow\n",
    "# from langchain.schema.runnable import Runnable\n",
    "# from langgraph.graph import StateGraph\n",
    "\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import ChatAgentMessage, ChatAgentResponse\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a4683c9-0b5c-4e6a-93dd-fa9e6d9e821a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "json.dumps({\"time_stamp\": \"2015-07\", \"machine_id\": 1, \"temperature\": 20, \"vibration\": 1.5, \"pressure\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35b1636d-460c-47bc-9c84-6e1987f084ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class LangGraphChatAgent(ChatAgent):\n",
    "    def __init__(self, agent: CompiledStateGraph):\n",
    "        self.agent = agent\n",
    "\n",
    "    def predict(self, messages: list[ChatAgentMessage], **kwargs) -> ChatAgentResponse:\n",
    "        messages = self._convert_messages_to_dict(messages)\n",
    "        input = json.loads(messages[0][\"content\"])\n",
    "        result = self.agent.invoke(input)[\"suggestion\"]\n",
    "        outputs = [ChatAgentMessage(id=str(uuid.uuid4()), role=\"assistant\", content=result)]\n",
    "        return ChatAgentResponse(messages=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b100a756-6cb0-4af6-a2f4-8273f3623a89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "chat_agent = LangGraphChatAgent(agent)\n",
    "\n",
    "test = {\n",
    "    \"timestamp\": datetime.now(),\n",
    "    \"machine_id\": 2,\n",
    "    \"temperature\": 25,\n",
    "    \"vibration\": 1.5,\n",
    "    \"pressure\": 3,\n",
    "}\n",
    "\n",
    "messages = [ChatAgentMessage(role=\"user\", content=json.dumps(test, default=str))]\n",
    "output = chat_agent.predict(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49c4d58e-9353-4a5a-8019-c41064984891",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output.messages[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a09d410-8985-49ab-8e5b-c0a4e74061b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from agent import AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12da90be-8510-4eb2-be84-172631b04a70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from mlflow.types.agent import ChatAgentMessage\n",
    "import json\n",
    "\n",
    "test = {\n",
    "    \"timestamp\": datetime.now(),\n",
    "    \"machine_id\": 2,\n",
    "    \"temperature\": 65,\n",
    "    \"vibration\": 5,\n",
    "    \"pressure\": 1,\n",
    "}\n",
    "\n",
    "messages = [ChatAgentMessage(role=\"user\", content=json.dumps(test, default=str))]\n",
    "output = AGENT.predict(messages)\n",
    "output.messages[0].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f08990b2-143f-49ec-870c-0f140eb2721c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Log agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0911f425-d927-4fde-80e6-611e3df3a9ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pkg_resources import get_distribution\n",
    "import mlflow\n",
    "\n",
    "test = {\n",
    "    \"timestamp\": datetime.now(),\n",
    "    \"machine_id\": 2,\n",
    "    \"temperature\": 65,\n",
    "    \"vibration\": 5,\n",
    "    \"pressure\": 1,\n",
    "}\n",
    "\n",
    "input_example = {\"messages\": messages}\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"pm_agent\",\n",
    "        python_model=\"agent.py\",\n",
    "        # resources=resources,\n",
    "        # input_example=[input_example],\n",
    "        pip_requirements=[\n",
    "            f\"databricks-connect=={get_distribution('databricks-connect').version}\",\n",
    "            f\"mlflow=={get_distribution('mlflow').version}\",\n",
    "            f\"databricks-langchain=={get_distribution('databricks-langchain').version}\",\n",
    "            f\"langgraph=={get_distribution('langgraph').version}\",\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "447d6d0f-c3b3-497f-8f05-50ad5a049702",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc1cc2c0-9265-42e3-be6f-eca6381a6fdd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register the model to Unity Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a6d3a4a-14d2-4060-a5e8-56202aafdeb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# TODO: define the catalog, schema, and model name for your UC model\n",
    "catalog = \"workspace\"\n",
    "schema = \"genai_demo\"\n",
    "model_name = \"pm_agent\"\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cbf1c62-4e97-4fe7-9a0d-3ca2b8d3c9fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "version = 1\n",
    "agent = mlflow.pyfunc.load_model(f\"models:/{UC_MODEL_NAME}/{version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6f64149-7e09-4138-a88f-8c5a6f259ee8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test = {\n",
    "    \"timestamp\": datetime.now(),\n",
    "    \"machine_id\": 2,\n",
    "    \"temperature\": 65,\n",
    "    \"vibration\": 5,\n",
    "    \"pressure\": 1,\n",
    "}\n",
    "\n",
    "input_data = {\"messages\": [{\"role\": \"user\", \"content\": json.dumps(test, default=str)}]}\n",
    "\n",
    "agent.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eae69ce9-078c-4ebe-a3bd-52bc0121e857",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "06_chatagent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
