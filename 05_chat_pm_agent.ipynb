{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15376367-0287-4618-ad82-03ff0f70ca20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U langchain langgraph databricks-sdk databricks-vectorsearch\n",
    "%pip install databricks-sdk[openai]\n",
    "%pip install grandalf\n",
    "%pip install pyppeteer\n",
    "%pip install -U databricks-agents>=0.16.0 mlflow>=2.20.2 databricks-langchain databricks-openai\n",
    "%pip install --upgrade \"mlflow-skinny[databricks]\"\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42798886-ad4c-452a-8ddd-1ffe4ff3acf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Enables autoreload; learn more at https://docs.databricks.com/en/files/workspace-modules.html#autoreload-for-python-modules\n",
    "# To disable autoreload; run %autoreload 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3e371dd-ba51-471b-b803-6d178204445a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Predictive Maintenance Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1cbb8e7-34d2-46d6-8acf-86c4134ff3a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile chat_agent.py\n",
    "import os\n",
    "from typing import Any, Generator, Optional, TypedDict, Annotated\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AnyMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from databricks_langchain import ChatDatabricks\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from mlflow.langchain.chat_agent_langgraph import parse_message\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentChunk,\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "import mlflow\n",
    "\n",
    "os.environ[\"MLFLOW_USE_DATABRICKS_SDK_MODEL_ARTIFACTS_REPO_FOR_UC\"] = \"True\"\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Configure\n",
    "CATALOG = \"workspace\"\n",
    "SCHEMA = \"genai_demo\"\n",
    "MODEL_NAME = \"isolation_forest_pm_model\"\n",
    "MODEL_NAME_FULL = f\"{CATALOG}.{SCHEMA}.{MODEL_NAME  }\"\n",
    "MODEL_VERSION = 1\n",
    "MODEL_URI = f'models:/{MODEL_NAME_FULL}/{MODEL_VERSION}'\n",
    "INDEX_NAME = \"maintenance_docs_index\"\n",
    "INDEX_NAME_FULL = f\"{CATALOG}.{SCHEMA}.{INDEX_NAME}\"\n",
    "LLM_MODEL = \"gpt-41\"\n",
    "TEMPERATURE = 0.1\n",
    "# LLM_MODEL = \"databricks-llama-4-maverick\"\n",
    "\n",
    "\n",
    "# Load resources: model, retriever, LLM\n",
    "ad_model = mlflow.sklearn.load_model(MODEL_URI)\n",
    "vsc = VectorSearchClient()\n",
    "index = vsc.get_index(index_name=INDEX_NAME_FULL)\n",
    "llm = ChatDatabricks(\n",
    "    target_uri=\"databricks\",\n",
    "    endpoint=LLM_MODEL,\n",
    "    temperature=TEMPERATURE,\n",
    ")\n",
    "\n",
    "\n",
    "# Define tools\n",
    "@tool\n",
    "def anomaly_detector(temperature: float, vibration: float, pressure: float) -> str:\n",
    "    \"\"\"\n",
    "    Detects anomalies in equipment behavior using vibration, pressure, and temperature.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        prediction = ad_model.predict([[temperature, vibration, pressure]])\n",
    "        result = \"Anomalous\" if prediction[0] == -1 else \"Normal\"\n",
    "        return f\"Anomaly Detection Result: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    \n",
    "\n",
    "@tool\n",
    "def vector_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Searches the vector index for machine manual documents.\"\"\"\n",
    "    try:\n",
    "        # Search the index with the query string\n",
    "        res = index.similarity_search(\n",
    "            query_text=query,\n",
    "            columns=[\"chunk_text\"],\n",
    "            num_results=1,\n",
    "            query_type=\"hybrid\"\n",
    "            )\n",
    "        context = \"\\n\\n\".join([r[0] for r in res[\"result\"][\"data_array\"]])\n",
    "        return context\n",
    "    except Exception as e:\n",
    "        return f\"Vector search error: {str(e)}\"\n",
    "\n",
    "\n",
    "tools = [anomaly_detector, vector_search]\n",
    "\n",
    "# Define Nodes\n",
    "system_prompt = SystemMessage(\n",
    "    content=(\n",
    "        \"You are a maintenance engineer tasked with addressing machine maintenance queries, conducting root cause analysis (RCA), and recommending appropriate resolutions.\" \"Use the search index to retrieve relevant information that supports accurate and context-aware responses.\"\n",
    "        \"If sensor data is provided, analyze it using the anomaly detection tool to assess whether the machine is operating normally or exhibiting anomalous behavior. \"\n",
    "        \"If an anomaly is detected and the user has not provided specific instructions, prompt them to confirm whether they would like to proceed with RCA and resolution. If instructions are provided, continue with the assigned task accordingly.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Add memory\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "def create_agent(llm, tools, system_prompt):\n",
    "\n",
    "    class AgentState(TypedDict):\n",
    "        messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "    # assistant node\n",
    "    def assistant_node(state: AgentState) -> AgentState:\n",
    "        msgs = state[\"messages\"]\n",
    "        # Prepend system prompt if first turn\n",
    "        if not any(isinstance(m, SystemMessage) for m in msgs):\n",
    "            msgs = [system_prompt] + msgs\n",
    "\n",
    "        response = llm_with_tools.invoke(msgs)\n",
    "        return {\"messages\": [response]}\n",
    "    \n",
    "    # Tools node\n",
    "    tools_node = ToolNode(tools)\n",
    "\n",
    "    # Build graph\n",
    "    builder = StateGraph(AgentState)\n",
    "    builder.add_node(\"assistant\", assistant_node)\n",
    "    builder.add_node(\"tools\", tools_node)\n",
    "\n",
    "    builder.add_edge(START, \"assistant\")\n",
    "    builder.add_conditional_edges(\n",
    "        \"assistant\",\n",
    "        tools_condition\n",
    "    )\n",
    "    builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "    agent = builder.compile(checkpointer=checkpointer)\n",
    "    # agent = builder.compile()\n",
    "\n",
    "    return agent\n",
    "\n",
    "\n",
    "class LangGraphChatAgent(ChatAgent):\n",
    "    def __init__(self, agent: CompiledStateGraph):\n",
    "        self.agent = agent\n",
    "\n",
    "    def predict(\n",
    "        self, \n",
    "        messages: list[ChatAgentMessage], \n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "        # res = self.agent.invoke(request)\n",
    "        if custom_inputs and 'configurable' in custom_inputs:\n",
    "            config = {\"configurable\": custom_inputs[\"configurable\"]}\n",
    "        else: \n",
    "            config = {\"configurable\": {'thread_id':99}}\n",
    "        res = self.agent.invoke(request, config)\n",
    "\n",
    "        response = [ChatAgentMessage(**parse_message(r)) for r in res[\"messages\"]]\n",
    "        return ChatAgentResponse(messages=response)\n",
    "    \n",
    "    def predict_stream(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> Generator[ChatAgentChunk, None, None]:\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "        if custom_inputs and 'configurable' in custom_inputs:\n",
    "            config = {\"configurable\": custom_inputs[\"configurable\"]}\n",
    "        else: \n",
    "            config = {\"configurable\": {'thread_id':1}}\n",
    "        for event in self.agent.stream(request, config, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                for m in node_data.get(\"messages\", []):\n",
    "                    msg = parse_message(m)\n",
    "                    yield ChatAgentChunk(delta=ChatAgentMessage(**msg))\n",
    "\n",
    "\n",
    "chat_pm_agent = create_agent(llm, tools, system_prompt)\n",
    "CHAT_AGENT = LangGraphChatAgent(chat_pm_agent)\n",
    "mlflow.models.set_model(CHAT_AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb26ec3f-4c26-4a64-983c-89f009a47bcc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Quick Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82abe080-dfdd-42a0-bf88-9836a2f80d89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from chat_agent import CHAT_AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b40593ec-0217-4807-a371-63e1bd7a1823",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"Hello, what can you assist?\"\n",
    "request = {\"messages\":[{\"role\": \"user\", \"content\": query}]}\n",
    "response = CHAT_AGENT.predict(request)\n",
    "print(response.messages[-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "337d5d30-1cf4-4a0e-a297-d99d92394a5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"The machine seems to be running hot. Could you look through the manuals to identify possible causes and suggest a solution?\"\n",
    "request = {\"messages\":[{\"role\": \"user\", \"content\": query}]}\n",
    "response = CHAT_AGENT.predict(request)\n",
    "print(response.messages[-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03222720-dbce-4fbe-956f-c99385021bf2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"The sensor readings from another machine are: temperature at 20°C, vibration at 1.5mm/s, and pressure at 30 PSI. Is it functioning as expected?\"\n",
    "request = {\"messages\":[{\"role\": \"user\", \"content\": query}]}\n",
    "response = CHAT_AGENT.predict(request)\n",
    "print(response.messages[-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9de403b-868d-494a-8b1e-f3335edbb1f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"The most recent sensor data from a different machine shows a temperature of 45°C, a vibration level of 3.5mm/s, and a pressure reading of 25 PSI. What do you think?\"\n",
    "request = {\"messages\":[{\"role\": \"user\", \"content\": query}]}\n",
    "response = CHAT_AGENT.predict(request)\n",
    "print(response.messages[-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9babd093-7905-41db-8fa3-b23e99acb058",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"Yes, proceed with a root cause analysis (RCA) and recommend appropriate resolutions for the issue\"\n",
    "request = {\"messages\":[{\"role\": \"user\", \"content\": query}]}\n",
    "response = CHAT_AGENT.predict(request)\n",
    "print(response.messages[-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb0143df-9c51-41aa-a8df-0abda91beb0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Log and Register Agent to Unity Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "270fddf7-4ae4-45ea-9dc9-4e3c1812c92b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Log the Agent\n",
    "import os\n",
    "import mlflow\n",
    "from pkg_resources import get_distribution\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.models.resources import DatabricksVectorSearchIndex, DatabricksServingEndpoint\n",
    "from mlflow.models.auth_policy import SystemAuthPolicy, UserAuthPolicy, AuthPolicy\n",
    "\n",
    "from chat_agent import INDEX_NAME_FULL, MODEL_NAME_FULL, LLM_MODEL, MODEL_VERSION\n",
    "\n",
    "\n",
    "resources = [\n",
    "    DatabricksVectorSearchIndex(index_name=INDEX_NAME_FULL),\n",
    "    DatabricksServingEndpoint(endpoint_name=LLM_MODEL),\n",
    "]\n",
    "\n",
    "auth_policy = AuthPolicy(\n",
    "    system_auth_policy=SystemAuthPolicy(resources=resources),\n",
    "    user_auth_policy=UserAuthPolicy(api_scopes=[\n",
    "        \"catalog.connections\",            # for Unity Catalog access\n",
    "    ])\n",
    ")\n",
    "\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"chat_pm_agent\",\n",
    "        python_model=\"chat_agent.py\",\n",
    "        auth_policy=auth_policy,\n",
    "        pip_requirements=[\n",
    "            f\"databricks-connect=={get_distribution('databricks-connect').version}\",\n",
    "            f\"mlflow=={get_distribution('mlflow').version}\",\n",
    "            f\"databricks-langchain=={get_distribution('databricks-langchain').version}\",\n",
    "            f\"langgraph=={get_distribution('langgraph').version}\",\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00db14b7-7fd7-4b83-a99c-1cd46f84d178",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Register the agent\n",
    "CATALOG = \"workspace\"\n",
    "SCHEMA = \"genai_demo\"\n",
    "AGENT_NAME = 'chat_pm_agent'\n",
    "AGENT_NAME_FULL = f\"{CATALOG}.{SCHEMA}.{AGENT_NAME}\"\n",
    "registered_model_info = mlflow.register_model(model_uri=logged_agent_info.model_uri, name=AGENT_NAME_FULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47df54aa-b7ae-4749-9b3a-f15be0e4744a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test the Registered Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dbd9a3a-c26b-43d5-b351-16290a7e9dd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "CATALOG = \"workspace\"\n",
    "SCHEMA = \"genai_demo\"\n",
    "AGENT_NAME = 'chat_pm_agent'\n",
    "AGENT_VERSION = 1\n",
    "AGENT_NAME_FULL = f\"models:/{CATALOG}.{SCHEMA}.{AGENT_NAME}/{AGENT_VERSION}\"\n",
    "chat_agent_loaded = mlflow.pyfunc.load_model(AGENT_NAME_FULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5716b96-202c-4d9a-ad32-1381d5c33de2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"Hello, what can you assist?\"\n",
    "request = {\"messages\":[{\"role\": \"user\", \"content\": query}]}\n",
    "response = chat_agent_loaded.predict(request)\n",
    "print(response['messages'][-1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92c34c3f-99c7-4f5e-b385-037dac9f2384",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Deploy the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fe94a06-6e07-45cd-9b17-00a1f50b97d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "AGENT_VERSION = 3\n",
    "agents.deploy(AGENT_NAME_FULL, AGENT_VERSION)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6025039881537450,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "05_chat_pm_agent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
