{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c4ae94a-cf15-4e2e-9b92-56c37bf604bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U langchain langgraph databricks-sdk databricks-vectorsearch\n",
    "%pip install databricks-sdk[openai]\n",
    "%pip install grandalf\n",
    "%pip install pyppeteer\n",
    "%pip install -U databricks-agents>=0.16.0 mlflow>=2.20.2 databricks-langchain databricks-openai\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42798886-ad4c-452a-8ddd-1ffe4ff3acf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Enables autoreload; learn more at https://docs.databricks.com/en/files/workspace-modules.html#autoreload-for-python-modules\n",
    "# To disable autoreload; run %autoreload 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3e371dd-ba51-471b-b803-6d178204445a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Predictive Maintenance Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9250c2e5-3661-4422-a3f1-5a9d086d27d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile flow_agent.py\n",
    "# Import dependencies\n",
    "from typing import Any, Optional\n",
    "import uuid\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "from pydantic import BaseModel\n",
    "import mlflow\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentChunk,\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "from databricks_langchain import ChatDatabricks\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "# Configure\n",
    "CATALOG = \"workspace\"\n",
    "SCHEMA = \"genai_demo\"\n",
    "MODEL_NAME = \"isolation_forest_pm_model\"\n",
    "MODEL_VERSION = 1\n",
    "MODEL_NAME_FULL = f\"models:/{CATALOG}.{SCHEMA}.{MODEL_NAME}/{MODEL_VERSION}\"\n",
    "INDEX_NAME = \"maintenance_docs_index\"\n",
    "INDEX_NAME_FULL = f\"{CATALOG}.{SCHEMA}.{INDEX_NAME}\"\n",
    "# LLM_MODEL = \"databricks-llama-4-maverick\"\n",
    "LLM_MODEL = \"gpt-41\"\n",
    "TEMPERATURE = 0.1\n",
    "\n",
    "\n",
    "# Define State Schema\n",
    "class AgentState(BaseModel):\n",
    "    timestamp: datetime\n",
    "    machine_id: int\n",
    "    temperature: float\n",
    "    vibration: float\n",
    "    pressure: float\n",
    "    # Normal operating ranges\n",
    "    normal_temp: tuple[float, float] = (20, 36)\n",
    "    normal_vibration: tuple[float, float] = (1, 2.2)\n",
    "    normal_pressure: tuple[float, float] = (2, 4.5)\n",
    "    # RCA logs\n",
    "    is_anomaly: bool = False\n",
    "    raw_query: str = \"\"\n",
    "    query: str = \"\"\n",
    "    context: str = \"\"\n",
    "    suggestion: str = \"\"\n",
    "\n",
    "\n",
    "# Load trained model from MLflow\n",
    "ad_model = mlflow.sklearn.load_model(MODEL_NAME_FULL)\n",
    "\n",
    "# Initialize vector retriever\n",
    "vsc = VectorSearchClient()\n",
    "index = vsc.get_index(index_name=INDEX_NAME_FULL)\n",
    "\n",
    "# Initialize LLM (Maverick)\n",
    "llm = ChatDatabricks(\n",
    "    target_uri=\"databricks\",\n",
    "    endpoint=LLM_MODEL,\n",
    "    temperature=TEMPERATURE,\n",
    ")\n",
    "\n",
    "\n",
    "# Define Nodes\n",
    "def detect_anomaly(state: AgentState) -> dict:\n",
    "    X = [[state.temperature, state.vibration, state.pressure]]\n",
    "    state.is_anomaly = ad_model.predict(X)[0] == -1\n",
    "    return {\"is_anomaly\": state.is_anomaly}\n",
    "\n",
    "\n",
    "def query_otimization(state: AgentState):\n",
    "    raw_query = (f\"Machine {state.machine_id} anomaly: T={state.temperature} [normal {state.normal_temp[0] - state.normal_temp[1]}], \"\n",
    "                 f\"V={state.vibration} [normal {state.normal_vibration[0]} - {state.normal_vibration[1]}], \"\n",
    "                 f\"P={state.pressure} [normal {state.normal_pressure[0]} - {state.normal_pressure[1]}]\")\n",
    "    \n",
    "    q_opt_msg = [\n",
    "        {\"role\":\"system\",\"content\":\"Rewrite the following to a concise, technical search query focusing on deviation from normal operation.\"},\n",
    "        {\"role\":\"user\",\"content\":raw_query}\n",
    "    ]\n",
    "\n",
    "    q_opt = llm.invoke(q_opt_msg).content\n",
    "    return {\"raw_query\": raw_query, \"query\": q_opt}\n",
    "\n",
    "def vector_search(state: AgentState):\n",
    "    hits = index.similarity_search(query_text=state.query, columns=[\"chunk_text\"], num_results=2, query_type=\"hybrid\")\n",
    "    context = \"\\n\\n\".join(hit[0] for hit in hits[\"result\"][\"data_array\"])\n",
    "    return {\"context\": context}\n",
    "\n",
    "def rca(state: AgentState):\n",
    "    prompt = [\n",
    "        {\"role\":\"system\",\"content\":\"You're an engineer analyzing machinery anomalies.\"},\n",
    "        {\"role\":\"user\",\"content\":\n",
    "         f\"Anomaly details:\\n{state.raw_query}\\n\\nContext:\\n{state.context}\\n\\nProvide root cause and maintenance actions.\"}\n",
    "    ]\n",
    "    response = llm.invoke(prompt)\n",
    "    suggestion = response.content\n",
    "    return {\"suggestion\": suggestion}\n",
    "\n",
    "\n",
    "\n",
    "def normal(state: AgentState) -> dict:\n",
    "    suggestion = \"✅ Machine is operating properly.\"\n",
    "    state.suggestion = suggestion\n",
    "    return {\"suggestion\": \"✅ Machine is operating properly.\"}\n",
    "\n",
    "def create_agent():\n",
    "    workflow = StateGraph(AgentState)\n",
    "    workflow.add_node(\"detect_anomaly\", detect_anomaly)\n",
    "    workflow.add_node(\"query_optimization\", query_otimization)\n",
    "    workflow.add_node(\"vector_search\", vector_search)\n",
    "    workflow.add_node(\"rca\", rca)\n",
    "\n",
    "    workflow.add_edge(START, \"detect_anomaly\")\n",
    "    workflow.add_conditional_edges(\"detect_anomaly\",\n",
    "        lambda s: \"query_optimization\" if s.is_anomaly else \"normal\",\n",
    "        {\"query_optimization\":\"query_optimization\", \"normal\": \"normal\"}\n",
    "    )\n",
    "    workflow.add_node(\"normal\", normal)\n",
    "    workflow.add_edge(\"normal\", END)\n",
    "    workflow.add_edge(\"query_optimization\", \"vector_search\")\n",
    "    workflow.add_edge(\"vector_search\", \"rca\")\n",
    "    workflow.add_edge(\"rca\", END)\n",
    "\n",
    "    agent = workflow.compile()\n",
    "    return agent\n",
    "\n",
    "\n",
    "class LangGraphChatAgent(ChatAgent):\n",
    "    def __init__(self, agent: CompiledStateGraph):\n",
    "        self.agent = agent\n",
    "    def predict(\n",
    "        self, \n",
    "        messages: list[ChatAgentMessage], \n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        messages = self._convert_messages_to_dict(messages)\n",
    "        request = json.loads(messages[-1]['content'])\n",
    "        response = self.agent.invoke(request)\n",
    "        return ChatAgentResponse(messages=[ChatAgentMessage(role=\"assistant\", content=response[\"suggestion\"], id=str((uuid.uuid4())))])\n",
    "        # return [ChatAgentMessage(role=\"assistant\", content=response[\"suggestion\"], id=str((uuid.uuid4())))]\n",
    "\n",
    "flow_agent = create_agent()\n",
    "FLOW_AGENT = LangGraphChatAgent(flow_agent)\n",
    "mlflow.models.set_model(FLOW_AGENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df326e44-288b-4ca6-a9c3-7f9dd4e4788c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from flow_agent import flow_agent\n",
    "print(flow_agent.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2c58a24-1bf3-48ee-9681-887c175a028f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "from flow_agent import FLOW_AGENT\n",
    "\n",
    "sensor_data_normal = {\n",
    "    \"timestamp\": str(datetime.now()), \n",
    "    \"machine_id\": 1, \n",
    "    \"temperature\": 20, \n",
    "    \"vibration\": 1.5, \n",
    "    \"pressure\": 30\n",
    "    }\n",
    "\n",
    "request = {\"messages\": [{\"role\": \"user\", \"content\": json.dumps(sensor_data_normal)}]}\n",
    "response = FLOW_AGENT.predict(request)\n",
    "print(response.messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b01eb3f4-d04c-4071-9b22-70224a4d17a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sensor_data_abnormal = {\n",
    "    \"timestamp\": str(datetime.now()), \n",
    "    \"machine_id\": 1, \n",
    "    \"temperature\": 45, \n",
    "    \"vibration\": 3.5, \n",
    "    \"pressure\": 25\n",
    "    }\n",
    "\n",
    "request = {\"messages\": [{\"role\": \"user\", \"content\": json.dumps(sensor_data_abnormal)}]}\n",
    "response = FLOW_AGENT.predict(request)\n",
    "print(response.messages[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7640de64-7593-4606-a983-f39daad9039c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Log and Register Agent to Unity Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21465ddf-8b95-40e8-b40f-902cf5d4566c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from pkg_resources import get_distribution\n",
    "\n",
    "\n",
    "sensor_data = {\n",
    "    \"timestamp\": str(datetime.now()), \n",
    "    \"machine_id\": 1, \n",
    "    \"temperature\": 20, \n",
    "    \"vibration\": 1.5, \n",
    "    \"pressure\": 30\n",
    "    }\n",
    "\n",
    "input_example = {\"messages\": [{\"role\": \"user\", \"content\": json.dumps(sensor_data)}]}\n",
    "\n",
    "# Log the agent\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"flow_pm_agent\",\n",
    "        python_model=\"flow_agent.py\",\n",
    "        input_example=input_example,\n",
    "        pip_requirements=[\n",
    "            f\"databricks-connect=={get_distribution('databricks-connect').version}\",\n",
    "            f\"mlflow=={get_distribution('mlflow').version}\",\n",
    "            f\"databricks-langchain=={get_distribution('databricks-langchain').version}\",\n",
    "            f\"langgraph=={get_distribution('langgraph').version}\",\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bbbd086-750c-4eb9-b6b0-a1913d3413b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Register the agent\n",
    "CATALOG = \"workspace\"\n",
    "SCHEMA = \"genai_demo\"\n",
    "AGENT_NAME = 'flow_pm_agent'\n",
    "AGENT_NAME_FULL = f\"{CATALOG}.{SCHEMA}.{AGENT_NAME}\"\n",
    "registered_model_info = mlflow.register_model(model_uri=logged_agent_info.model_uri, name=AGENT_NAME_FULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83f2c9dd-02cb-4b53-bbdd-f464c6717048",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test the Registered Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b10c0cb3-cb49-4517-9e73-adebb0ee88a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "CATALOG = \"workspace\"\n",
    "SCHEMA = \"genai_demo\"\n",
    "AGENT_NAME = 'flow_pm_agent'\n",
    "AGENT_VERSION = 1\n",
    "AGENT_NAME_FULL = f\"models:/{CATALOG}.{SCHEMA}.{AGENT_NAME}/{AGENT_VERSION}\"\n",
    "flow_agent_loaded = mlflow.pyfunc.load_model(AGENT_NAME_FULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cd9f111-eefc-4d16-b9d2-e26eeec26c65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sensor_data_abnormal = {\n",
    "    \"timestamp\": str(datetime.now()), \n",
    "    \"machine_id\": 1, \n",
    "    \"temperature\": 45, \n",
    "    \"vibration\": 3.5, \n",
    "    \"pressure\": 25\n",
    "    }\n",
    "\n",
    "request = {\"messages\": [{\"role\": \"user\", \"content\": json.dumps(sensor_data_abnormal)}]}\n",
    "response = flow_agent_loaded.predict(request)\n",
    "print(response['messages'][0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56cd5f3a-a6d9-49fd-b330-c328dd3c018c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_workflow_pm_agent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
